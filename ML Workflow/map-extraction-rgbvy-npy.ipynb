{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import dlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from scipy import signal\n",
    "from sklearn import preprocessing\n",
    "import os\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ORIGINAL_VIDEOS_OUTPUT_PATH = './ppg maps/PPG_maps_128x32/original'\n",
    "MANIPULATED_VIDEOS_OUTPUT_PATH = './ppg maps/PPG_maps_128x32/df'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_ppg_maps(vid_path, vid_num, outpath):\n",
    "\n",
    "    # Define the input video file path\n",
    "    video_path = vid_path\n",
    "\n",
    "    # Open the video file\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "    # Get the frames per second (fps) and total frame count\n",
    "    fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    # Set the desired number of frames per segment\n",
    "    frames_per_segment = 128  # Set to 128 frames per segment\n",
    "\n",
    "    detector = dlib.get_frontal_face_detector()\n",
    "    predictor = dlib.shape_predictor(\n",
    "        \"shape_predictor_68_face_landmarks/shape_predictor_68_face_landmarks (1).dat\"\n",
    "    )  # You need to download this file\n",
    "    # detector.set_min_detection_confidence(0.5)\n",
    "    # Initialize variables to keep track of segment number and frames\n",
    "    segment_number = 1\n",
    "    frame_count = 0\n",
    "    ppgmap = np.empty([128, 32, 5])\n",
    "    ind = 0\n",
    "    gabor_kernel = cv2.getGaborKernel((3, 3), 1, 0, 1, 0.5, 0)\n",
    "\n",
    "    while True:\n",
    "        # print(\"hi\")\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        frame = cv2.resize(frame, (854, 480))\n",
    "\n",
    "        # Convert the frame to grayscale for face detection\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        if len(detector(gray)) == 0:\n",
    "            continue\n",
    "\n",
    "        face = detector(gray)[0]\n",
    "        landmarks = predictor(gray, face)\n",
    "\n",
    "        # Extract the coordinates of the nose (e.g., landmark point 30)\n",
    "        nose_x = landmarks.part(30).x\n",
    "        nose_y = landmarks.part(30).y\n",
    "\n",
    "        # Define the ROI around the nose\n",
    "        roi_size_width = 64\n",
    "        roi_size_height = 32\n",
    "        roi_x = nose_x - roi_size_width // 2\n",
    "        roi_y = nose_y - roi_size_height // 2\n",
    "\n",
    "        # Ensure ROI coordinates are within bounds\n",
    "        roi_x = max(0, roi_x)\n",
    "        roi_y = max(0, roi_y)\n",
    "        roi_x_end = min(frame.shape[1], roi_x + roi_size_width)\n",
    "        roi_y_end = min(frame.shape[0], roi_y + roi_size_height)\n",
    "\n",
    "        # Extract the ROI\n",
    "        roi = frame[roi_y:roi_y_end, roi_x:roi_x_end]\n",
    "\n",
    "        # Calculate subregion size\n",
    "        subregion_width = roi_size_width // 8  # 8 subregions horizontally\n",
    "        subregion_height = roi_size_height // 4  # 4 subregions vertically\n",
    "\n",
    "        subregions_r = np.zeros(32)\n",
    "        subregions_y = np.zeros(32)\n",
    "        subregions_v = np.zeros(32)\n",
    "        subregions_b = np.zeros(32)\n",
    "        subregions_g = np.zeros(32)\n",
    "        k = 0\n",
    "        for i in range(4):\n",
    "            for j in range(8):\n",
    "                left = j * subregion_width\n",
    "                upper = i * subregion_height\n",
    "                right = (j + 1) * subregion_width\n",
    "                lower = (i + 1) * subregion_height\n",
    "                subregion = roi[upper:lower, left:right]\n",
    "\n",
    "                roi_ycbcr = cv2.cvtColor(subregion, cv2.COLOR_BGR2YCrCb)\n",
    "                roi_hsv = cv2.cvtColor(subregion, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "                y_layer = roi_ycbcr[:, :, 0]\n",
    "                v_layer = roi_hsv[:, :, 2]\n",
    "                r_layer = subregion[:, :, 0]\n",
    "                b_layer = subregion[:, :, 1]\n",
    "                g_layer = subregion[:, :, 2]\n",
    "\n",
    "                print(y_layer.shape)\n",
    "                y_layer = cv2.filter2D(y_layer, cv2.CV_32F, gabor_kernel)\n",
    "                v_layer = cv2.filter2D(v_layer, cv2.CV_32F, gabor_kernel)\n",
    "                r_layer = cv2.filter2D(r_layer, cv2.CV_32F, gabor_kernel)\n",
    "                b_layer = cv2.filter2D(b_layer, cv2.CV_32F, gabor_kernel)\n",
    "                g_layer = cv2.filter2D(g_layer, cv2.CV_32F, gabor_kernel)\n",
    "                print(y_layer.shape)\n",
    "                print()\n",
    "                y_comp = np.mean(y_layer)\n",
    "                v_comp = np.mean(v_layer)\n",
    "                rv = np.mean(r_layer)\n",
    "                bv = np.mean(b_layer)\n",
    "                gv = np.mean(g_layer)\n",
    "\n",
    "                subregions_r[k] = rv\n",
    "                subregions_b[k] = bv\n",
    "                subregions_g[k] = gv\n",
    "                subregions_y[k] = y_comp\n",
    "                subregions_v[k] = v_comp\n",
    "                k += 1\n",
    "\n",
    "        ppgmap[ind, :, 0] = subregions_r\n",
    "        ppgmap[ind, :, 1] = subregions_b\n",
    "        ppgmap[ind, :, 2] = subregions_g\n",
    "        ppgmap[ind, :, 3] = subregions_y\n",
    "        ppgmap[ind, :, 4] = subregions_v\n",
    "        # print(ppgmap[ind])\n",
    "        ind += 1\n",
    "        frame_count += 1\n",
    "        # curr_seg.append(frame)\n",
    "        # print(ppgmap[ind])\n",
    "        if frame_count == frames_per_segment:\n",
    "            vidnum = vid_num[:3]\n",
    "            min_values = np.min(ppgmap, axis=(0, 1))\n",
    "            max_values = np.max(ppgmap, axis=(0, 1))\n",
    "            # print(min_values.shape)\n",
    "            scaled_data = (\n",
    "                (ppgmap - min_values) / (max_values - min_values) * 255.0\n",
    "            ).astype(np.uint8)\n",
    "            # cv2.imwrite(f'{outpath}/{vidnum}_{segment_number}.png',scaled_data)\n",
    "            np.save(f\"{vidnum}_{segment_number}.npy\", scaled_data)\n",
    "            segment_number += 1\n",
    "            ppgmap = np.empty([128, 32, 5])\n",
    "            ind = 0\n",
    "            frame_count = 0\n",
    "    cap.release()\n",
    "    print(vid_path, \" completed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manipulated Videos\n",
    "files=os.listdir('datasets/face-forensics++/c23/manipulated_sequences/Deepfakes/c23/videos')\n",
    "count=1\n",
    "for file in files:\n",
    "    if(os.path.exists(f'./ppg maps/PPG_maps_128x32/{file[:3]}_1.png')):\n",
    "        print('PPG already created', count)\n",
    "        count+=1\n",
    "        continue\n",
    "    create_ppg_maps(\n",
    "        f'datasets/face-forensics++/c23/manipulated_sequences/Deepfakes/c23/videos/{file}',\n",
    "        file,\n",
    "        MANIPULATED_VIDEOS_OUTPUT_PATH\n",
    "    )\n",
    "    print(count)\n",
    "    count+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Original Videos\n",
    "files=os.listdir('datasets/face-forensics++/c23/original_sequences/youtube/c23/videos')\n",
    "count=1\n",
    "for file in files:\n",
    "    if(os.path.exists(f'./ppg maps/PPG_maps_128x32/{file[:3]}_1.png')):\n",
    "        print('PPG already created', count)\n",
    "        count+=1\n",
    "        continue\n",
    "    create_ppg_maps(\n",
    "        f'datasets/face-forensics++/c23/original_sequences/youtube/c23/videos/{file}',\n",
    "        file,\n",
    "        ORIGINAL_VIDEOS_OUTPUT_PATH\n",
    "    )\n",
    "    print(count)\n",
    "    count+=1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
